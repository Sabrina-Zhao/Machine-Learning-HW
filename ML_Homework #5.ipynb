{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ywSRtNI4s5h"
   },
   "source": [
    "# 0.) Import the Credit Card Fraud Data From CCLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "nsG1QV154GYZ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Iku0T8Ou4Lcu",
    "outputId": "c533459a-89a7-4d6f-978b-ea2295ace9e7"
   },
   "outputs": [],
   "source": [
    "#drive.mount('/content/gdrive/', force_remount = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "KJQfo8mz43Kz"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"fraudTest.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 481
    },
    "id": "mKWSRv-q98wE",
    "outputId": "29838bae-3f83-4216-f0da-f7ea7ee6ee69"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>trans_date_trans_time</th>\n",
       "      <th>cc_num</th>\n",
       "      <th>merchant</th>\n",
       "      <th>category</th>\n",
       "      <th>amt</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>gender</th>\n",
       "      <th>street</th>\n",
       "      <th>...</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>city_pop</th>\n",
       "      <th>job</th>\n",
       "      <th>dob</th>\n",
       "      <th>trans_num</th>\n",
       "      <th>unix_time</th>\n",
       "      <th>merch_lat</th>\n",
       "      <th>merch_long</th>\n",
       "      <th>is_fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-06-21 12:14:25</td>\n",
       "      <td>2291163933867244</td>\n",
       "      <td>fraud_Kirlin and Sons</td>\n",
       "      <td>personal_care</td>\n",
       "      <td>2.86</td>\n",
       "      <td>Jeff</td>\n",
       "      <td>Elliott</td>\n",
       "      <td>M</td>\n",
       "      <td>351 Darlene Green</td>\n",
       "      <td>...</td>\n",
       "      <td>33.9659</td>\n",
       "      <td>-80.9355</td>\n",
       "      <td>333497</td>\n",
       "      <td>Mechanical engineer</td>\n",
       "      <td>1968-03-19</td>\n",
       "      <td>2da90c7d74bd46a0caf3777415b3ebd3</td>\n",
       "      <td>1371816865</td>\n",
       "      <td>33.986391</td>\n",
       "      <td>-81.200714</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-06-21 12:14:33</td>\n",
       "      <td>3573030041201292</td>\n",
       "      <td>fraud_Sporer-Keebler</td>\n",
       "      <td>personal_care</td>\n",
       "      <td>29.84</td>\n",
       "      <td>Joanne</td>\n",
       "      <td>Williams</td>\n",
       "      <td>F</td>\n",
       "      <td>3638 Marsh Union</td>\n",
       "      <td>...</td>\n",
       "      <td>40.3207</td>\n",
       "      <td>-110.4360</td>\n",
       "      <td>302</td>\n",
       "      <td>Sales professional, IT</td>\n",
       "      <td>1990-01-17</td>\n",
       "      <td>324cc204407e99f51b0d6ca0055005e7</td>\n",
       "      <td>1371816873</td>\n",
       "      <td>39.450498</td>\n",
       "      <td>-109.960431</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-06-21 12:14:53</td>\n",
       "      <td>3598215285024754</td>\n",
       "      <td>fraud_Swaniawski, Nitzsche and Welch</td>\n",
       "      <td>health_fitness</td>\n",
       "      <td>41.28</td>\n",
       "      <td>Ashley</td>\n",
       "      <td>Lopez</td>\n",
       "      <td>F</td>\n",
       "      <td>9333 Valentine Point</td>\n",
       "      <td>...</td>\n",
       "      <td>40.6729</td>\n",
       "      <td>-73.5365</td>\n",
       "      <td>34496</td>\n",
       "      <td>Librarian, public</td>\n",
       "      <td>1970-10-21</td>\n",
       "      <td>c81755dbbbea9d5c77f094348a7579be</td>\n",
       "      <td>1371816893</td>\n",
       "      <td>40.495810</td>\n",
       "      <td>-74.196111</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2020-06-21 12:15:15</td>\n",
       "      <td>3591919803438423</td>\n",
       "      <td>fraud_Haley Group</td>\n",
       "      <td>misc_pos</td>\n",
       "      <td>60.05</td>\n",
       "      <td>Brian</td>\n",
       "      <td>Williams</td>\n",
       "      <td>M</td>\n",
       "      <td>32941 Krystal Mill Apt. 552</td>\n",
       "      <td>...</td>\n",
       "      <td>28.5697</td>\n",
       "      <td>-80.8191</td>\n",
       "      <td>54767</td>\n",
       "      <td>Set designer</td>\n",
       "      <td>1987-07-25</td>\n",
       "      <td>2159175b9efe66dc301f149d3d5abf8c</td>\n",
       "      <td>1371816915</td>\n",
       "      <td>28.812398</td>\n",
       "      <td>-80.883061</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-06-21 12:15:17</td>\n",
       "      <td>3526826139003047</td>\n",
       "      <td>fraud_Johnston-Casper</td>\n",
       "      <td>travel</td>\n",
       "      <td>3.19</td>\n",
       "      <td>Nathan</td>\n",
       "      <td>Massey</td>\n",
       "      <td>M</td>\n",
       "      <td>5783 Evan Roads Apt. 465</td>\n",
       "      <td>...</td>\n",
       "      <td>44.2529</td>\n",
       "      <td>-85.0170</td>\n",
       "      <td>1126</td>\n",
       "      <td>Furniture designer</td>\n",
       "      <td>1955-07-06</td>\n",
       "      <td>57ff021bd3f328f8738bb535c302a31b</td>\n",
       "      <td>1371816917</td>\n",
       "      <td>44.959148</td>\n",
       "      <td>-85.884734</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 trans_date_trans_time            cc_num  \\\n",
       "0           0   2020-06-21 12:14:25  2291163933867244   \n",
       "1           1   2020-06-21 12:14:33  3573030041201292   \n",
       "2           2   2020-06-21 12:14:53  3598215285024754   \n",
       "3           3   2020-06-21 12:15:15  3591919803438423   \n",
       "4           4   2020-06-21 12:15:17  3526826139003047   \n",
       "\n",
       "                               merchant        category    amt   first  \\\n",
       "0                 fraud_Kirlin and Sons   personal_care   2.86    Jeff   \n",
       "1                  fraud_Sporer-Keebler   personal_care  29.84  Joanne   \n",
       "2  fraud_Swaniawski, Nitzsche and Welch  health_fitness  41.28  Ashley   \n",
       "3                     fraud_Haley Group        misc_pos  60.05   Brian   \n",
       "4                 fraud_Johnston-Casper          travel   3.19  Nathan   \n",
       "\n",
       "       last gender                       street  ...      lat      long  \\\n",
       "0   Elliott      M            351 Darlene Green  ...  33.9659  -80.9355   \n",
       "1  Williams      F             3638 Marsh Union  ...  40.3207 -110.4360   \n",
       "2     Lopez      F         9333 Valentine Point  ...  40.6729  -73.5365   \n",
       "3  Williams      M  32941 Krystal Mill Apt. 552  ...  28.5697  -80.8191   \n",
       "4    Massey      M     5783 Evan Roads Apt. 465  ...  44.2529  -85.0170   \n",
       "\n",
       "   city_pop                     job         dob  \\\n",
       "0    333497     Mechanical engineer  1968-03-19   \n",
       "1       302  Sales professional, IT  1990-01-17   \n",
       "2     34496       Librarian, public  1970-10-21   \n",
       "3     54767            Set designer  1987-07-25   \n",
       "4      1126      Furniture designer  1955-07-06   \n",
       "\n",
       "                          trans_num   unix_time  merch_lat  merch_long  \\\n",
       "0  2da90c7d74bd46a0caf3777415b3ebd3  1371816865  33.986391  -81.200714   \n",
       "1  324cc204407e99f51b0d6ca0055005e7  1371816873  39.450498 -109.960431   \n",
       "2  c81755dbbbea9d5c77f094348a7579be  1371816893  40.495810  -74.196111   \n",
       "3  2159175b9efe66dc301f149d3d5abf8c  1371816915  28.812398  -80.883061   \n",
       "4  57ff021bd3f328f8738bb535c302a31b  1371816917  44.959148  -85.884734   \n",
       "\n",
       "   is_fraud  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2_YuJa4IFKda",
    "outputId": "7e387d76-2dd6-472c-d598-5994ef2b9fda"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\赵恨阑\\AppData\\Local\\Temp\\ipykernel_28228\\2282180580.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_select[\"trans_date_trans_time\"] = pd.to_datetime(df_select[\"trans_date_trans_time\"])\n",
      "C:\\Users\\赵恨阑\\AppData\\Local\\Temp\\ipykernel_28228\\2282180580.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_select[\"time_var\"] = [i.second for i in df_select[\"trans_date_trans_time\"]]\n"
     ]
    }
   ],
   "source": [
    "df_select = df[[\"trans_date_trans_time\", \"category\", \"amt\", \"city_pop\", \"is_fraud\"]]\n",
    "\n",
    "df_select[\"trans_date_trans_time\"] = pd.to_datetime(df_select[\"trans_date_trans_time\"])\n",
    "df_select[\"time_var\"] = [i.second for i in df_select[\"trans_date_trans_time\"]]\n",
    "\n",
    "X = pd.get_dummies(df_select, [\"category\"]).drop([\"trans_date_trans_time\", \"is_fraud\"], axis = 1)\n",
    "y = df[\"is_fraud\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8VsnpGe9-B3p"
   },
   "source": [
    "# 1.) Use scikit learn preprocessing to split the data into 70/30 in out of sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "1tpCDMW198ym"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "FZvnpERK981d"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "JvCzIdgO983i"
   },
   "outputs": [],
   "source": [
    "X_test, X_holdout, y_test, y_holdout = train_test_split(X_test, y_test, test_size = .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "f7APv9N3986a"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_holdout = scaler.transform(X_holdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lbkpNPyN-Gnk"
   },
   "source": [
    "# 2.) Make three sets of training data (Oversample, Undersample and SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "gTTVciVkqopH"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "gG88uxbiV4lZ"
   },
   "outputs": [],
   "source": [
    "ros = RandomOverSampler()\n",
    "over_X, over_y = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "rus = RandomUnderSampler()\n",
    "under_X, under_y = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "smote = SMOTE()\n",
    "smote_X, smote_y = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bIJx2jvD-KEI"
   },
   "source": [
    "# 3.) Train three logistic regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "QhVMq92zvz4s"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "NvwomEoaGAgN"
   },
   "outputs": [],
   "source": [
    "over_log = LogisticRegression().fit(over_X, over_y)\n",
    "\n",
    "under_log = LogisticRegression().fit(under_X, under_y)\n",
    "\n",
    "smote_log = LogisticRegression().fit(smote_X, smote_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PeurmqI4-OoC"
   },
   "source": [
    "# 4.) Test the three models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8tpSsOC0xsKs",
    "outputId": "fee6e3f0-6c06-489e-90da-59237e609bca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8801674704287531"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "over_log.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zwq8KTmsXhFY",
    "outputId": "7c01f959-58d8-44c6-e955-39fe84168d8a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.886093716259987"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "under_log.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DjgQ8BQM99WR",
    "outputId": "a4f3fa30-e8f3-43f4-b562-959b200488e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8782600350296312"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smote_log.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "IF_H74Ht-RIL"
   },
   "outputs": [],
   "source": [
    "# We see SMOTE performing with higher accuracy but is ACCURACY really the best measure?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6isBwtmL-R4p"
   },
   "source": [
    "# 5.) Which performed best in Out of Sample metrics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "9fwAhujT-RN4"
   },
   "outputs": [],
   "source": [
    "# Sensitivity here in credit fraud is more important as seen from last class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "POIuy3rH-RQv"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "e42UoedMK6eq"
   },
   "outputs": [],
   "source": [
    "y_true = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2mc_RyrHK6hX",
    "outputId": "408bb243-3c83-4337-97f5-21f57718360f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[73112,  9916],\n",
       "       [   73,   257]], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = over_log.predict(X_test)\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xT6gNjLuK6jS",
    "outputId": "2ed847ca-c7a5-414b-d45a-2e7acadfc9d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Over Sample Sensitivity :  0.7787878787878788\n"
     ]
    }
   ],
   "source": [
    "print(\"Over Sample Sensitivity : \", cm[1,1] /( cm[1,0] + cm[1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FTHhw9P1K6lY",
    "outputId": "cadf0e8b-2b60-4ac8-fa81-275d3fab8c6f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[73606,  9422],\n",
       "       [   73,   257]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = under_log.predict(X_test)\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g14fgEkT-RTV",
    "outputId": "72b0902b-c2f5-46c7-c49c-83126c75c94f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Under Sample Sensitivity :  0.7787878787878788\n"
     ]
    }
   ],
   "source": [
    "print(\"Under Sample Sensitivity : \", cm[1,1] /( cm[1,0] + cm[1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_iZ217d8LAR0",
    "outputId": "6d498a8f-bdd9-445d-97cc-6e4eec82574b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[72953, 10075],\n",
       "       [   73,   257]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = smote_log.predict(X_test)\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X5bfByOALAUk",
    "outputId": "a7071ed7-f896-4825-90f4-612a0603697a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE Sample Sensitivity :  0.7787878787878788\n"
     ]
    }
   ],
   "source": [
    "print(\"SMOTE Sample Sensitivity : \", cm[1,1] /( cm[1,0] + cm[1,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aQa3sanl-XUk"
   },
   "source": [
    "# 6.) Pick two features and plot the two classes before and after SMOTE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "MDSBmS_usbeJ"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot concatenate object of type '<class 'numpy.ndarray'>'; only Series and DataFrame objs are valid",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m raw_temp \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([X_train, y_train], axis \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mE:\\anaconda\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:372\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    370\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 372\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[0;32m    373\u001b[0m     objs,\n\u001b[0;32m    374\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m    375\u001b[0m     ignore_index\u001b[38;5;241m=\u001b[39mignore_index,\n\u001b[0;32m    376\u001b[0m     join\u001b[38;5;241m=\u001b[39mjoin,\n\u001b[0;32m    377\u001b[0m     keys\u001b[38;5;241m=\u001b[39mkeys,\n\u001b[0;32m    378\u001b[0m     levels\u001b[38;5;241m=\u001b[39mlevels,\n\u001b[0;32m    379\u001b[0m     names\u001b[38;5;241m=\u001b[39mnames,\n\u001b[0;32m    380\u001b[0m     verify_integrity\u001b[38;5;241m=\u001b[39mverify_integrity,\n\u001b[0;32m    381\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    382\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m    383\u001b[0m )\n\u001b[0;32m    385\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32mE:\\anaconda\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:462\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    457\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, (ABCSeries, ABCDataFrame)):\n\u001b[0;32m    458\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    459\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot concatenate object of type \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(obj)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    460\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monly Series and DataFrame objs are valid\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    461\u001b[0m         )\n\u001b[1;32m--> 462\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m    464\u001b[0m     ndims\u001b[38;5;241m.\u001b[39madd(obj\u001b[38;5;241m.\u001b[39mndim)\n\u001b[0;32m    466\u001b[0m \u001b[38;5;66;03m# get the sample\u001b[39;00m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;66;03m# want the highest ndim that we have, and must be non-empty\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;66;03m# unless all objs are empty\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot concatenate object of type '<class 'numpy.ndarray'>'; only Series and DataFrame objs are valid"
     ]
    }
   ],
   "source": [
    "raw_temp = pd.concat([X_train, y_train], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9QA-y6HCslBR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 465
    },
    "id": "vVaHpqf9wHj7",
    "outputId": "105a15c4-f26c-4210-f97c-4b4c3112344e"
   },
   "outputs": [],
   "source": [
    "#plt.scatter(raw_temp[raw_temp[\"is_fraud\"] == 0][\"amt\"], raw_temp[raw_temp[\"is_fraud\"] == 0][\"city_pop\"])\n",
    "\n",
    "plt.scatter(raw_temp[raw_temp[\"is_fraud\"] == 1][\"amt\"], raw_temp[raw_temp[\"is_fraud\"] == 1][\"city_pop\"])\n",
    "plt.legend([\"Fraud\", \"Not Fraud\"])\n",
    "plt.xlabel(\"Amount\")\n",
    "plt.ylabel(\"Population\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YphNDj12aFhP"
   },
   "outputs": [],
   "source": [
    "raw_temp = pd.concat([smote_X, smote_y], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "id": "G-MUv66T-RZE",
    "outputId": "a845731d-5a52-4480-d5eb-8dd58de8c3ca"
   },
   "outputs": [],
   "source": [
    "#plt.scatter(raw_temp[raw_temp[\"is_fraud\"] == 0][\"amt\"], raw_temp[raw_temp[\"is_fraud\"] == 0][\"city_pop\"])\n",
    "\n",
    "plt.scatter(raw_temp[raw_temp[\"is_fraud\"] == 1][\"amt\"], raw_temp[raw_temp[\"is_fraud\"] == 1][\"city_pop\"])\n",
    "plt.legend([ \"Not Fraud\", \"Fraud\"])\n",
    "plt.xlabel(\"Amount\")\n",
    "plt.ylabel(\"Population\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wjt1pnzgZcuO"
   },
   "source": [
    "# 7.) We want to compare oversampling, Undersampling and SMOTE across our 3 models (Logistic Regression, Logistic Regression Lasso and Decision Trees).\n",
    "\n",
    "# Make a dataframe that has a dual index and 9 Rows.\n",
    "# Calculate: Sensitivity, Specificity, Precision, Recall and F1 score. for out of sample data.\n",
    "# Notice any patterns across perfomance for this model. Does one totally out perform the others IE. over/under/smote or does a model perform better DT, Lasso, LR?\n",
    "# Choose what you think is the best model and why. test on Holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "0tIC3Nd1bx-N"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampling_methods = {\n",
    "    \"over\": RandomOverSampler(),\n",
    "    \"under\": RandomUnderSampler(),\n",
    "    \"smote\": SMOTE()\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"LOG\": LogisticRegression(),\n",
    "    \"LASSO\": LogisticRegression(penalty=\"l1\",C=2.,solver='liblinear'),\n",
    "    \"DTREE\":DecisionTreeClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_models = {}\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_perf_metric(y_true,y_pred):\n",
    "    tn,fp,fn,tp = confusion_matrix(y_true,y_pred).ravel()\n",
    "    \n",
    "    sensitivity = tp/(tp+fn)\n",
    "    specificity = tn/(tn+fp)\n",
    "    precision = precision_score(y_true,y_pred)\n",
    "    recall = recall_score(y_true,y_pred)\n",
    "    f1 = f1_score(y_true,y_pred)\n",
    "    \n",
    "    return(sensitivity, specificity, precision, recall, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for resample_key, resampler in resampling_methods.items():\n",
    "    resample_X, resample_y = resampler.fit_resample(X_train,y_train)\n",
    "    \n",
    "    for model_key, model in model_configs.items():\n",
    "        combined_key = f\"{resample_key}_{model_key}\"\n",
    "        m = model.fit(resample_X,resample_y)\n",
    "        trained_models[combined_key]=m\n",
    "       \n",
    "        y_pred=m.predict(X_test)\n",
    "        \n",
    "        sensitivity,specificity,precision,recall,f1=calc_perf_metric(y_test,y_pred)\n",
    "        \n",
    "        results.append({\"Model\":combined_key,\n",
    "                       \"Sensitivity\":sensitivity,\n",
    "                       \"Specificity\":specificity,\n",
    "                       \"Precision\":precision,\n",
    "                       \"Recall\":recall,\n",
    "                       \"F1\":f1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>over_LOG</td>\n",
       "      <td>0.778788</td>\n",
       "      <td>0.877343</td>\n",
       "      <td>0.024615</td>\n",
       "      <td>0.778788</td>\n",
       "      <td>0.047721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>over_LASSO</td>\n",
       "      <td>0.778788</td>\n",
       "      <td>0.877367</td>\n",
       "      <td>0.024619</td>\n",
       "      <td>0.778788</td>\n",
       "      <td>0.047730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>over_DTREE</td>\n",
       "      <td>0.527273</td>\n",
       "      <td>0.998422</td>\n",
       "      <td>0.570492</td>\n",
       "      <td>0.527273</td>\n",
       "      <td>0.548031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>under_LOG</td>\n",
       "      <td>0.778788</td>\n",
       "      <td>0.868418</td>\n",
       "      <td>0.022983</td>\n",
       "      <td>0.778788</td>\n",
       "      <td>0.044649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>under_LASSO</td>\n",
       "      <td>0.778788</td>\n",
       "      <td>0.867912</td>\n",
       "      <td>0.022897</td>\n",
       "      <td>0.778788</td>\n",
       "      <td>0.044487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>under_DTREE</td>\n",
       "      <td>0.960606</td>\n",
       "      <td>0.949788</td>\n",
       "      <td>0.070664</td>\n",
       "      <td>0.960606</td>\n",
       "      <td>0.131645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>smote_LOG</td>\n",
       "      <td>0.778788</td>\n",
       "      <td>0.877824</td>\n",
       "      <td>0.024709</td>\n",
       "      <td>0.778788</td>\n",
       "      <td>0.047899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>smote_LASSO</td>\n",
       "      <td>0.778788</td>\n",
       "      <td>0.877897</td>\n",
       "      <td>0.024723</td>\n",
       "      <td>0.778788</td>\n",
       "      <td>0.047925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>smote_DTREE</td>\n",
       "      <td>0.715152</td>\n",
       "      <td>0.993171</td>\n",
       "      <td>0.293898</td>\n",
       "      <td>0.715152</td>\n",
       "      <td>0.416593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Model  Sensitivity  Specificity  Precision    Recall        F1\n",
       "0     over_LOG     0.778788     0.877343   0.024615  0.778788  0.047721\n",
       "1   over_LASSO     0.778788     0.877367   0.024619  0.778788  0.047730\n",
       "2   over_DTREE     0.527273     0.998422   0.570492  0.527273  0.548031\n",
       "3    under_LOG     0.778788     0.868418   0.022983  0.778788  0.044649\n",
       "4  under_LASSO     0.778788     0.867912   0.022897  0.778788  0.044487\n",
       "5  under_DTREE     0.960606     0.949788   0.070664  0.960606  0.131645\n",
       "6    smote_LOG     0.778788     0.877824   0.024709  0.778788  0.047899\n",
       "7  smote_LASSO     0.778788     0.877897   0.024723  0.778788  0.047925\n",
       "8  smote_DTREE     0.715152     0.993171   0.293898  0.715152  0.416593"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Decision Tree (DTREE): The sensitivity (recall) for both oversampling and undersampling techniques is relatively lower compared to other models. The specificity is high, indicating a good ability to correctly identify non-events. Precision is higher for oversampling than undersampling.\n",
    "\n",
    "For Logistic Regression (LOG): Similar to the Decision Tree, sensitivity is relatively low for both oversampling and undersampling. Specificity is high, suggesting good performance in identifying non-events. Precision is very low, indicating a high number of false positives.\n",
    "\n",
    "For LASSO: Sensitivity and specificity are comparable to Logistic Regression and Decision Tree. Precision is also low, and the F1 score is generally low for all sampling techniques. Sampling Techniques (Over, Under, SMOTE):\n",
    "\n",
    "Across all three models (LOG, LASSO, DTREE), there is no consistent pattern favoring one sampling technique over the others in terms of performance.SMOTE tends to have slightly higher sensitivity and specificity for both Logistic Regression and LASSO compared to oversampling and undersampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no a clear winner but a well-considered tradeoff is model:smote_LASSO. This model balance the sensitivity and f1, meanwhile having a relatively high specificity."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
